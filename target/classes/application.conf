prefilterConfig {

  input {
    topic: "radius"

  }

  output {
    topicCon: "radiusConLog",
    topicLoad: "radiusLoadLog",
    topicError: "raidusErroLog"
  }


  stopWords: ["a", "an", "the"]

  windowDuration: 10s

  slideDuration: 10s

  sparkConfig {
    "spark.master": "local[2]"
    "spark.app.name": "prefilter-Radius-Log"
    //es test
    "es.port": "9200"
    "es.nodes":"localhost"
    "es.http.timeout":"5m"
    "es.scroll.size":"50"
    "es.index.auto.create":"true"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

  streamingBatchDuration: 5s

  streamingCheckPointDir: ${java.io.tmpdir}
  //streamingCheckpointDir: "/tmp"

  sourceKafka {
    // kafka brokers
    //"metadata.broker.list": "localhost:9092"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"
    "bootstrap.servers": "localhost:9092"
    "group.id": "raidus-streaming-log"
    //String De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    //Array[Byte]
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //Do not set dererializer for source!!
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"

  }

  prefilterSinkKafka {
    // kafka bootstrap
    "bootstrap.servers": "localhost:9092"
    // ack from all in-sync replicas
    "acks": "all"
    // reduce buffer size from default 32M to 8M
    "buffer.memory": "8388608"
    // block if buffer is full
    "block.on.buffer.full": "true"
    // retry forever
    "retries": "2147483647"
    "retry.backoff.ms": "1500"
    //String Se-De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    "key.serializer" : "org.apache.kafka.common.serialization.StringSerializer"
    "value.serializer": "org.apache.kafka.common.serialization.StringSerializer"
    // Byte Array
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
  }

}

wordCountJob {

  input {
    topic: "input"

  }

  output {
    topic: "output"
  }


  stopWords: ["a", "an", "the"]

  windowDuration: 10s

  slideDuration: 10s

  spark {
    "spark.master": "local[*]"
    "spark.app.name": "example-spark-kafka"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

  streamingBatchDuration: 5s
  streamingCheckpointDir: ${java.io.tmpdir}
  //streamingCheckpointDir: "/tmp"

  kafkaSource {
    // kafka brokers
    //"metadata.broker.list": "localhost:9092"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"
    "bootstrap.servers": "localhost:9092"
    "group.id": "spark-streaming-notes"
    //String De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    //Array[Byte]
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //Do not set dererializer for source!!
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"

  }

  kafkaSink {
    // kafka bootstrap
    "bootstrap.servers": "localhost:9092"
    // ack from all in-sync replicas
    "acks": "all"
    // reduce buffer size from default 32M to 8M
    "buffer.memory": "8388608"
    // block if buffer is full
    "block.on.buffer.full": "true"
    // retry forever
    "retries": "2147483647"
    "retry.backoff.ms": "1500"
    //String Se-De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    "key.serializer" : "org.apache.kafka.common.serialization.StringSerializer"
    "value.serializer": "org.apache.kafka.common.serialization.StringSerializer"
    // Byte Array
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
  }
}
